{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(num):\n",
    "    if num == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return num / abs(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_classify(x, theta, theta_0):\n",
    "    \"\"\"Uses the given theta, theta_0, to linearly classify the given data x. This is our hypothesis or hypothesis class.\n",
    "\n",
    "    :param x:\n",
    "    :param theta:\n",
    "    :param theta_0:\n",
    "    :return: 1 if the given x is classified as positive, -1 if it is negative, and 0 if it lies on the hyperplane.\n",
    "    \"\"\"\n",
    "    # Todo: Implement the linear classifier here that classifies x given theta, theta_0, and returns the result.\n",
    "    res = np.dot(theta.T, x)[0] + theta_0\n",
    "    return sign(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(prediction, actual):\n",
    "    \"\"\"Computes the loss between the given prediction and actual values.\n",
    "\n",
    "    :param prediction:\n",
    "    :param actual:\n",
    "    :return: 2 if prediction is wrong, 0 if prediction is correct\n",
    "    \"\"\"\n",
    "    # Todo: Implement the loss between a predicted and actual value here, and return the loss.\n",
    "    return abs(prediction - actual) # if prediction is correct, returns 0, else returns 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_n(h, data, labels, L, theta, theta_0):\n",
    "    \"\"\"Computes the error for the given data using the given hypothesis and loss.\n",
    "\n",
    "    :param h: Hypothesis class, for example a linear classifier.\n",
    "    :param data: A d x n matrix where d is the number of data dimensions and n the number of examples.\n",
    "    :param labels: A 1 x n matrix with the label (actual value) for each data point.\n",
    "    :param L: A loss function to compute the error between the prediction and label.\n",
    "    :param theta:\n",
    "    :param theta_0:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Todo: Compute the training loss E_n here and return it.\n",
    "    predictions = [linear_classify(x, theta, theta_0) for x in data.T] # turning the data sideways so that each entry has 1 x n dimensions\n",
    "    loss_sum = np.sum([L(label, prediction) for label, prediction in zip(labels, predictions)])\n",
    "    return loss_sum / data.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_linear_classifier(data, labels, params={}, hook=None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data: A d x n matrix where d is the number of data dimensions and n the number of examples.\n",
    "    :param labels: A 1 x n matrix with the label (actual value) for each data point.\n",
    "    :param params: A dict, containing a key k, which is a positive integer number of steps to run\n",
    "    :param hook: An optional hook function that is called in each iteration of the algorithm.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    k = params.get('k', 100)  # if k is not in params, default to 100\n",
    "    (d, n) = data.shape\n",
    "    # Todo: Implement the Random Linear Classifier learning algorithm here.\n",
    "    # Note: To call the hook function, use the following line inside your training loop:\n",
    "    #if hook: hook((theta, theta_0))\n",
    "    smallest_error = np.inf\n",
    "    theta_best = np.zeros((d, 1))\n",
    "    theta_zero_best = 0\n",
    "    for _ in range(k):\n",
    "        theta = np.random.uniform(-20, 20, (d, 1))\n",
    "        theta_0 = np.random.randint(-20, 20)\n",
    "        #print(E_n(None, data, labels, Loss, theta, theta_0))\n",
    "        if hook: hook((theta, theta_0))\n",
    "        if E_n(None, data, labels, Loss, theta, theta_0) < smallest_error:\n",
    "            theta_best = np.copy(theta)\n",
    "            theta_zero_best = np.copy(theta_0)\n",
    "            smallest_error = E_n(None, data, labels, Loss, theta_best, theta_zero_best)\n",
    "    return theta_best, theta_zero_best, E_n(None, data, labels, Loss, theta_best, theta_zero_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(data, labels, params={}, hook=None):\n",
    "    \"\"\"The Perceptron learning algorithm.\n",
    "\n",
    "    :param data: A d x n matrix where d is the number of data dimensions and n the number of examples.\n",
    "    :param labels: A 1 x n matrix with the label (actual value) for each data point.\n",
    "    :param params: A dict, containing a key T, which is a positive integer number of steps to run\n",
    "    :param hook: An optional hook function that is called in each iteration of the algorithm.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    T = params.get('T', 100)  # if T is not in params, default to 100\n",
    "    (d, n) = data.shape\n",
    "    theta = np.zeros((d, 1))\n",
    "    #theta_0 = 0\n",
    "    for _ in range(T):\n",
    "        if hook : hook((theta, theta_0))\n",
    "        for index, entry in enumerate(data.T):\n",
    "            if labels[index] * linear_classify(entry, theta, theta_0) <= 0:\n",
    "                theta = np.add(theta, (labels[index] * entry.reshape(d, 1)))\n",
    "                #theta_0 += labels[index]\n",
    "    return theta, theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_separator(plot_axes, theta, theta_0):\n",
    "    \"\"\"Plots the linear separator defined by theta, theta_0, into the given plot_axes.\n",
    "\n",
    "    :param plot_axes: Matplotlib Axes object\n",
    "    :param theta:\n",
    "    :param theta_0:\n",
    "    \"\"\"\n",
    "\n",
    "    # One way we can plot the intercept is to compute the parametric line equation from the implicit form.\n",
    "    # compute the y-intercept by setting x1 = 0 and then solving for x2:\n",
    "    y_intercept = -theta_0 / theta[1]\n",
    "    # compute the slope (-theta[0]/theta[1], I think)\n",
    "    slope = -theta[0] / theta[1]\n",
    "    # Then compute two points using:\n",
    "    xmin, xmax = -15, 15\n",
    "    # Note: It's not ideal to only plot the lines in a fixed region, but it makes this code simple for now.\n",
    "\n",
    "    p1_y = slope * xmin + y_intercept\n",
    "    p2_y = slope * xmax + y_intercept\n",
    "\n",
    "    # Plot the separator:\n",
    "    plot_axes.plot([xmin, xmax], [p1_y.flatten(), p2_y.flatten()], '-')\n",
    "    # Plot the normal:\n",
    "    # Note: The normal might not appear perpendicular on the plot if ax.axis('equal') is not set - but it is\n",
    "    # perpendicular. Resize the plot window to equal axes to verify.\n",
    "    plot_axes.arrow((xmin + xmax) / 2, (p1_y.flatten() + p2_y.flatten()) / 2, float(theta[0]), float(theta[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.]\n",
      " [ 3.]] 0\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-0d0baa04a3e3>:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  y_intercept = -theta_0 / theta[1]\n",
      "<ipython-input-17-0d0baa04a3e3>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  slope = -theta[0] / theta[1]\n",
      "c:\\Users\\ivanb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\patches.py:1338: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  verts = np.dot(coords, M) + (x + dx, y + dy)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's create some training data and labels:\n",
    "#   X is a d x n matrix where d is the number of data dimensions and n the number of examples. So each data point\n",
    "#     is a column vector.\n",
    "#   y is a 1 x n matrix with the label (actual value) for each data point.\n",
    "X = np.array([\n",
    "    [2, 0, -1],\n",
    "    [0, 2, -1],\n",
    "    ])\n",
    "y = np.array([-1, 1, -1])\n",
    "\n",
    "# To test your algorithm on a larger dataset, uncomment the following code. It generates uniformly distributed\n",
    "# random data in 2D, along with their labels.\n",
    "#X = np.random.uniform(low=-10, high=10, size=(2, 20))  # d=2, n=20\n",
    "#y = np.sign(np.dot(np.transpose([[3], [4]]), X) + 6)[0]  # theta=[3, 4], theta_0=6\n",
    "\n",
    "# Plot positive data green, negative data red:\n",
    "colors = np.choose(y > 0, np.transpose(np.array(['r', 'g']))).flatten()\n",
    "plt.ion()  # enable matplotlib interactive mode\n",
    "fig, ax = plt.subplots()  # create an empty plot and retrieve the 'ax' handle\n",
    "ax.scatter(X[0, :], X[1, :], c=colors, marker='o')\n",
    "# Set up a pretty 2D plot:\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_xlim(-20, 20)\n",
    "ax.set_ylim(-20, 20)\n",
    "ax.grid(True, which='both')\n",
    "ax.axhline(color='black', linewidth=0.5)\n",
    "ax.axvline(color='black', linewidth=0.5)\n",
    "ax.set_title(\"Linear classification\")\n",
    "\n",
    "\n",
    "# We'll define a hook function that we'll use to plot the separator at each step of the learning algorithm:\n",
    "def hook(params):\n",
    "    (th, th0) = params\n",
    "    plot_separator(ax, th, th0)\n",
    "\n",
    "\n",
    "# Run the RLC or Perceptron: (uncomment the following lines to call the learning algorithms)\n",
    "#theta, theta_0, error = random_linear_classifier(X, y, {\"k\": 10}, hook = None)\n",
    "theta, theta_0 = perceptron(X, y, {\"T\": 10}, hook=None)\n",
    "# Plot the returned separator:\n",
    "plot_separator(ax, theta, theta_0)\n",
    "print(theta, theta_0)\n",
    "#print(theta, theta_0, E_n(None, X, y, Loss, theta, theta_0))\n",
    "\n",
    "# Run the RLC, plot E_n over various k:\n",
    "# Todo: Your code\n",
    "def plot_RLC(ks, iterations):\n",
    "    \"\"\"\n",
    "    Plots the error by a linear classificator over Ks different values of k and taking an average of a given number of iterations.\n",
    "    Args:\n",
    "        ks - the range of values of k\n",
    "        iterations - the number of iterations per value of k\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for n in range(1, ks):\n",
    "        avg_error = 0\n",
    "        for _ in range (iterations):\n",
    "            theta, theta_0, error = random_linear_classifier(X, y, {\"k\": n}, hook = None)\n",
    "            avg_error += error\n",
    "        errors.append(avg_error/10)\n",
    "    plt.plot(list(range(1, ks)), errors)\n",
    "\n",
    "print(\"Finished.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b79c34c0bc451fa60e640cef16a699410f160f3627e84908fe4a419d6ecde43"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
